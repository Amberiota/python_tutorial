{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 11 Python Files\n",
    "\n",
    "## 9.1 File Objects\n",
    "\n",
    "> File objects can be used to access not only normal disk files, but also any other type of “file” that uses that abstraction.\n",
    "\n",
    "> Remember, files are simply a contiguous sequence of bytes.\n",
    "\n",
    "## 9.2 File Built-in Functions `open()` and `file()`\n",
    "\n",
    "1. Basic format\n",
    "\n",
    "`file_object = open(file_name, access_mode='r', buffering=-1)`\n",
    "\n",
    "access_mode: `r`: read, `w`: write, `a`: append, `b`: byte, `U`: universal\n",
    "\n",
    "if the file exists, `w` will remove contents inside, and write new content instead; `a` will ignore contents inside, and put new content behind.\n",
    "\n",
    "> When you use the 'U' flag to open a file, all line separators (or terminators) will be returned by Python via any file input method, i.e., read*(), as a NEWLINE character ( \\n ) regardless of what the line-endings are.\n",
    "\n",
    "> Note that UNS only applies to reading text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file '/Users/acepor/Work/online_course/notebook/unicode.txt', mode 'r' at 0x10f9e3a50>\n"
     ]
    }
   ],
   "source": [
    "f_name = '/Users/acepor/Work/online_course/notebook/unicode.txt'\n",
    "data = open(f_name, 'r')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 File Built-in Methods\n",
    "\n",
    "> The read() method is used to read bytes directly into a string, reading at most the number of bytes indicated.\n",
    "\n",
    "> The readlines() method does not return a string like the other two input methods. Instead, it reads all (remaining) lines and returns them as a list of strings.\n",
    "\n",
    "> Line termination characters are not inserted between each line, so if desired, they must be added to the end of each line before writelines() is called.\n",
    "\n",
    "> When reading lines in from a file using file input methods like read() or readlines(), Python does not remove the line termination characters.\n",
    "\n",
    "> ! It is possible to lose output data that is buffered if you do not explicitly close a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read: \n",
      "Hello world\n",
      "Bonjour\n",
      "Hola\n",
      "\n",
      "readline: \n",
      "Hello world\n",
      "\n",
      "readlines: \n",
      "['Hello world\\n', 'Bonjour\\n', 'Hola\\n']\n",
      "\n",
      "file loop:\n",
      "Hello world\n",
      "\n",
      "Bonjour\n",
      "\n",
      "Hola\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = open(f_name, 'r')\n",
    "print('read: ')\n",
    "print(data.read())\n",
    "data = open(f_name, 'r')\n",
    "print('readline: ')\n",
    "print(data.readline())\n",
    "data = open(f_name, 'r')\n",
    "print('readlines: ')\n",
    "print(data.readlines())\n",
    "print\n",
    "print('file loop:')\n",
    "data = open(f_name, 'r')\n",
    "for line in data:\n",
    "    print(line)\n",
    "\n",
    "print\n",
    "with(open(f_name, 'a')) as f:\n",
    "    f.write('Hiya')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Pandas\n",
    "\n",
    "According to the [newest Pandas doc](http://pandas.pydata.org/pandas-docs/stable/io.html), Pandas supports reading and supporting these commonly-used file format: CSV, JSON, HTML, Local clipboard, MS Excel, HDF5 Format, Feather Format, Msgpack, Stata, SAS, Python Pickle Format, SQL, and Google Big Query. If we visualize these data formats, we can have a clearer idea:\n",
    "\n",
    "![pandoc file conversion map](http://acepor.github.io/images/pandas_relations.png)\n",
    "\n",
    "A comprehensive introduction of Pandas IO tools can be found [here](http://pandas.pydata.org/pandas-docs/stable/io.html). However, in this post, we will briefly introduce using Pandas to read / write some common file format.\n",
    "\n",
    "### CSV\n",
    "\n",
    "CSV (comma-separated-value) format is one of the most common formats in data processing. It is easy for both human and machine to read.\n",
    "\n",
    "\n",
    "`data = pd.read_csv(in_file, quote=0, sep=',', engine='c')`\n",
    "\n",
    "\n",
    "`quote` is to tell which quotation convention the data uses.\n",
    "\n",
    "If the `sep` set as `None` and `engine` as 'python', this function will automatically sniff the delimiter.\n",
    "\n",
    "`c` engine is much faster (at least 50%) than `python` engine, but `python` engine supports more features\n",
    "\n",
    "`data.to_csv(out_file, header=True, index=False)`\n",
    "\n",
    "If we want to keep header and index, we can set `header` and `index` as `True`, and vice versa.\n",
    "\n",
    "### TSV\n",
    "\n",
    "TSV (tab-separated-value) format is also very common, and Pandas can process it in a similar way as CSV.\n",
    "\n",
    "`data = pd.read_table(in_file, quote=0, sep='\\t', engine='c')`\n",
    "\n",
    "### JSON\n",
    "\n",
    "JSON has gain more popularity recently. It has more controls on data, but it is not very human-friendly. Because it has a number of orients, it is quite easy to get confused. Therefore, when we use Pandas to read a JSON file, we have to specify the orient. It could be `split`, `records`, `index`, `columns` or `values`. Moreover, it the file is line-based, we can set `lines` as `True`.\n",
    "\n",
    "`data = pd.read_json(in_file, orient='records', lines=False)`\n",
    "\n",
    "`data.to_json(out_file, orient='records', lines=False)`\n",
    "\n",
    "### MySQL\n",
    "\n",
    "MySQL is one of the most popular database, and `pandas` can easily read the data from it with the help of another Python library `sqlalchemy`.\n",
    "\n",
    "First, we use sqlalchemy to make a MySQL connection.\n",
    "\n",
    "`from sqlalchemy import create_engine`\n",
    "\n",
    "`def connect_db(host):\n",
    "    return create_engine(host)`\n",
    "\n",
    "Then, we give a SQL query to pandas, and query from the created connection. Just that simple, we can easiily get the queried result to a `pandas` Dataframe.\n",
    "\n",
    "`def mysql_df(sql, con):\n",
    "    df = pd.read_sql_query(sql=sql, con=con)\n",
    "    return df`\n",
    "\n",
    "## Advantages\n",
    "\n",
    "Using Pandas as a unified IO tool has two main advantages:\n",
    "\n",
    "    1. Pandas IO tools provide a significant performance increase when reading or writing data.\n",
    "    2. Pandas has very detailed document, so the learning curse is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
